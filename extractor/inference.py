from langchain_openai import AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate
import logging
import json
import re
import os
from datetime import datetime
from config.settings import settings

def setup_llm():
    """Setup Azure OpenAI LLM with proper configuration."""
    try:
        llm = AzureChatOpenAI(
            azure_deployment=settings.AZURE_OPENAI_DEPLOYMENT,
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_key=settings.AZURE_OPENAI_API_KEY,
            api_version=settings.AZURE_OPENAI_API_VERSION,
            temperature=settings.AI_TEMPERATURE,
            max_tokens=settings.AI_MAX_TOKENS
        )
        return llm
    except Exception as e:
        logging.error(f"Failed to setup LLM: {e}")
        return None

def save_debug_info(url, content, ai_response=None, error=None, extraction_type="ai_failure"):
    """Save debug information to debug folder when extraction fails."""
    try:
        # Create debug folder if it doesn't exist
        os.makedirs('debug', exist_ok=True)
        
        # Create timestamped debug filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        domain = url.replace('https://', '').replace('http://', '').replace('/', '_').replace(':', '_')
        debug_filename = f"debug/debug_{extraction_type}_{domain}_{timestamp}.txt"
        
        with open(debug_filename, 'w', encoding='utf-8') as f:
            f.write(f"DEBUG INFORMATION\n")
            f.write(f"================\n")
            f.write(f"URL: {url}\n")
            f.write(f"Timestamp: {datetime.now().isoformat()}\n")
            f.write(f"Extraction Type: {extraction_type}\n")
            f.write(f"Content Length: {len(content) if content else 0}\n")
            f.write(f"\n")
            
            if error:
                f.write(f"ERROR:\n{error}\n\n")
            
            if ai_response:
                f.write(f"AI RESPONSE:\n{ai_response}\n\n")
            
            f.write(f"CONTENT:\n")
            f.write(f"--------\n")
            f.write(content[:5000] if content else "No content")  # First 5000 chars
            f.write(f"\n\n")
            
        logging.info(f"Saved debug information to {debug_filename}")
        return debug_filename
    except Exception as e:
        logging.error(f"Could not save debug information: {e}")
        return None

def parse_fallback_content(content):
    """Parse fallback content that was generated by the crawler."""
    try:
        modules = []
        lines = content.split('\n')
        
        current_module = None
        for line in lines:
            line = line.strip()
            
            # Look for numbered module entries
            if re.match(r'^\d+\.\s+(.+)', line):
                if current_module:
                    modules.append(current_module)
                
                module_name = re.match(r'^\d+\.\s+(.+)', line).group(1)
                current_module = {
                    'name': module_name,
                    'description': '',
                    'submodules': {}
                }
            
            # Look for description lines
            elif line.startswith('Description:') and current_module:
                description = line.replace('Description:', '').strip()
                current_module['description'] = description
                
                # Add default submodules for fallback content
                current_module['submodules'] = {
                    f"{current_module['name']} Setup": f"Initial setup and configuration for {current_module['name'].lower()}",
                    f"{current_module['name']} Usage": f"How to use and implement {current_module['name'].lower()} effectively"
                }
        
        # Add the last module
        if current_module:
            modules.append(current_module)
        
        if modules:
            # Convert to new format
            formatted_modules = []
            for module in modules:
                formatted_modules.append({
                    'module': module['name'],
                    'Description': module['description'],
                    'Submodules': module['submodules']
                })
            return formatted_modules
        
    except Exception as e:
        logging.error(f"Failed to parse fallback content: {e}")
    
    return None

def extract_modules_heuristically(content):
    """Extract modules using heuristic methods when AI fails."""
    try:
        modules = []
        
        # Look for common patterns in documentation
        patterns = [
            # Headers (H1-H6)
            r'^#{1,6}\s+(.+)$',
            # Numbered lists
            r'^\d+\.\s+(.+)$',
            # Bullet points
            r'^[-*•]\s+(.+)$',
            # Bold text (potential headers)
            r'\*\*(.+?)\*\*',
            # Title case lines (potential headers)
            r'^([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s*$'
        ]
        
        lines = content.split('\n')
        potential_modules = {}
        current_section = None
        
        # First pass: identify sections and their content
        for i, line in enumerate(lines):
            line = line.strip()
            if len(line) < 5 or len(line) > 100:
                continue
                
            # Check if this looks like a header
            is_header = False
            for pattern in patterns[:4]:  # Use first 4 patterns for headers
                if re.match(pattern, line):
                    is_header = True
                    break
            
            if is_header:
                # Clean up the header
                clean_header = re.sub(r'^[#\d\.\-\*•\s]+', '', line).strip()
                clean_header = re.sub(r'[^\w\s-]', '', clean_header).strip()
                
                if len(clean_header) > 5 and len(clean_header) < 80:
                    current_section = clean_header
                    potential_modules[current_section] = {
                        'content': [],
                        'subheaders': []
                    }
            elif current_section and len(line) > 20:
                # Add content to current section
                potential_modules[current_section]['content'].append(line)
                
                # Check if this might be a subheader
                if (len(line) < 60 and 
                    not line.endswith('.') and 
                    ':' in line and 
                    len(line.split(':')[0]) < 40):
                    potential_modules[current_section]['subheaders'].append(line)
        
        # Second pass: create detailed modules
        for section_name, section_data in potential_modules.items():
            if len(section_data['content']) < 2:  # Skip sections with too little content
                continue
                
            # Create comprehensive description
            content_text = ' '.join(section_data['content'][:5])  # Use first 5 lines
            description = f"This section covers {section_name.lower()}. "
            
            # Add more context from content
            if len(content_text) > 100:
                description += content_text[:200] + "..."
            else:
                description += content_text
            
            # Create submodules from subheaders and content
            submodules = {}
            
            # Add submodules from subheaders
            for subheader in section_data['subheaders'][:3]:  # Limit to 3
                sub_name = subheader.split(':')[0].strip()
                sub_desc = subheader.split(':', 1)[1].strip() if ':' in subheader else f"Details about {sub_name.lower()}"
                
                if len(sub_desc) < 30:
                    sub_desc += f" This covers the configuration and usage of {sub_name.lower()} within {section_name.lower()}."
                
                submodules[sub_name] = sub_desc
            
            # Add general submodules if we don't have enough
            if len(submodules) < 2:
                submodules[f"{section_name} Overview"] = f"Comprehensive overview of {section_name.lower()} including basic concepts, setup procedures, and initial configuration steps."
                
                submodules[f"{section_name} Implementation"] = f"Detailed implementation guide for {section_name.lower()} including best practices, common use cases, and troubleshooting information."
            
            # Only add if we have at least 2 submodules with good descriptions
            if len(submodules) >= 2 and len(description) > 50:
                # Limit to 4 submodules
                limited_submodules = dict(list(submodules.items())[:4])
                modules.append({
                    'name': section_name,
                    'description': description,
                    'submodules': limited_submodules
                })
        
        # Only return if we have at least 2 quality modules
        if len(modules) >= 2:
            # Convert to new format
            formatted_modules = []
            for module in modules[:6]:  # Limit to 6 modules
                formatted_modules.append({
                    'module': module['name'],
                    'Description': module['description'],
                    'Submodules': module['submodules']
                })
            return formatted_modules
            
    except Exception as e:
        logging.error(f"Heuristic extraction failed: {e}")
    
    return None

def extract_modules_with_ai(content, url=""):
    """Extract modules using AI with comprehensive fallback handling."""
    
    logging.info(f"Starting extraction for {url}, content length: {len(content) if content else 0}")
    
    # Check if this is fallback content
    if "FALLBACK CONTENT FOR:" in content or "EXTRACTION FAILED FOR:" in content:
        logging.info(f"Processing fallback content for {url}")
        result = parse_fallback_content(content)
        if result and isinstance(result, list) and len(result) >= 1:  # Reduced from 2 to 1
            # Validate quality of fallback content
            valid_modules = []
            for module in result:
                if (isinstance(module, dict) and 
                    module.get('module') and len(module.get('module', '')) > 3 and  # Reduced from 5 to 3
                    module.get('Description') and len(module.get('Description', '')) > 30 and  # Reduced from 50 to 30
                    module.get('Submodules') and isinstance(module.get('Submodules'), dict) and
                    len(module.get('Submodules', {})) >= 1):  # Reduced from 2 to 1
                    valid_modules.append(module)
            
            if len(valid_modules) >= 1:  # Reduced from 2 to 1
                logging.info(f"Fallback content validation successful for {url}: {len(valid_modules)} modules")
                return valid_modules
            else:
                logging.warning(f"Fallback content quality insufficient for {url}")
                return None
        else:
            logging.warning(f"Fallback content parsing failed for {url}")
            return None
    
    # Try AI extraction first
    llm = setup_llm()
    if llm:
        try:
            logging.info(f"Attempting AI extraction for {url}")
            prompt = f"""
            Analyze the following documentation content and extract comprehensive, detailed modules and submodules.
            
            Content from: {url}
            
            Content:
            {content[:6000]}  # Increased content limit for better analysis
            
            IMPORTANT INSTRUCTIONS:
            1. Extract DETAILED modules with comprehensive descriptions (at least 2-3 sentences each)
            2. Include specific submodules with practical examples and use cases
            3. Focus on actionable information that users can implement
            4. Include technical details, parameters, and configuration options where available
            5. If you find step-by-step procedures, include them as submodules
            6. Extract troubleshooting information, best practices, and common issues
            7. Include API endpoints, code examples, or configuration snippets if present
            8. ONLY return results if you can extract meaningful, detailed information
            9. Each module should have at least 1-2 submodules with substantial content
            
            Return ONLY a JSON array in this exact format:
            [
                {{
                    "module": "Detailed Module Name",
                    "Description": "Comprehensive description explaining what this module covers, how it works, and when to use it. Include technical details and context.",
                    "Submodules": {{
                        "Specific Feature Name": "Detailed description of this specific feature, including steps, parameters, examples, or configuration details.",
                        "Another Feature": "Another detailed explanation with practical information, troubleshooting tips, or implementation guidance."
                    }}
                }},
                {{
                    "module": "Another Module Name",
                    "Description": "Another comprehensive description with technical details and context.",
                    "Submodules": {{
                        "Feature One": "Detailed explanation of feature one with implementation details."
                    }}
                }}
            ]
            
            VALIDATION RULES:
            - Each module must have at least 1 submodule
            - Each description must be at least 30 characters long
            - Only return if you can extract at least 1 meaningful module
            - Focus on depth over breadth
            - Return as a direct JSON array, not wrapped in an object
            
            Return only the JSON array, no other text.
            """
            
            response = llm.invoke(prompt)
            response_text = response.content.strip()
            logging.info(f"AI response received for {url}, length: {len(response_text)}")
            
            # Clean up the response
            response_text = response_text.replace('```json', '').replace('```', '').strip()
            
            # Try to parse JSON
            try:
                result = json.loads(response_text)
                logging.info(f"JSON parsed successfully for {url}, type: {type(result)}, length: {len(result) if isinstance(result, list) else 'N/A'}")
                
                if (result and isinstance(result, list) and len(result) >= 1):  # Reduced from 2 to 1
                    
                    # Validate module quality
                    valid_modules = []
                    for i, module in enumerate(result):
                        logging.info(f"Validating module {i+1} for {url}: {module.get('module', 'NO_NAME')}")
                        if (isinstance(module, dict) and 
                            module.get('module') and len(module.get('module', '')) > 3 and  # Reduced from 5 to 3
                            module.get('Description') and len(module.get('Description', '')) > 30 and  # Reduced from 50 to 30
                            module.get('Submodules') and isinstance(module.get('Submodules'), dict) and
                            len(module.get('Submodules', {})) >= 1):  # Reduced from 2 to 1
                            
                            # Validate submodules
                            valid_submodules = {}
                            for submodule_name, description in module['Submodules'].items():
                                if (isinstance(submodule_name, str) and
                                    len(submodule_name) > 3 and  # Reduced from 5 to 3
                                    isinstance(description, str) and
                                    len(description) > 20):  # Reduced from 30 to 20
                                    valid_submodules[submodule_name] = description
                            
                            if len(valid_submodules) >= 1:  # Reduced from 2 to 1
                                module['Submodules'] = valid_submodules
                                valid_modules.append(module)
                                logging.info(f"Module {i+1} validated successfully for {url}")
                            else:
                                logging.warning(f"Module {i+1} failed submodule validation for {url}")
                        else:
                            logging.warning(f"Module {i+1} failed basic validation for {url}")
                    
                    if len(valid_modules) >= 1:  # Reduced from 2 to 1
                        logging.info(f"AI extraction successful for {url} with {len(valid_modules)} detailed modules")
                        return valid_modules
                    else:
                        logging.warning(f"AI extraction didn't meet quality standards for {url}")
                        
            except json.JSONDecodeError as e:
                logging.warning(f"AI returned invalid JSON for {url}: {e}")
                # Save debug info for JSON parsing failure
                save_debug_info(url, content, response_text, str(e), "json_parse_failure")
                
                # Try to extract JSON from the response
                json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
                if json_match:
                    try:
                        result = json.loads(json_match.group())
                        if result and isinstance(result, list) and len(result) >= 1:  # Reduced from 2 to 1
                            # Validate the extracted JSON
                            valid_modules = []
                            for module in result:
                                if (isinstance(module, dict) and 
                                    module.get('module') and len(module.get('module', '')) > 3 and
                                    module.get('Description') and len(module.get('Description', '')) > 30 and
                                    module.get('Submodules') and isinstance(module.get('Submodules'), dict) and
                                    len(module.get('Submodules', {})) >= 1):
                                    valid_modules.append(module)
                            
                            if len(valid_modules) >= 1:  # Reduced from 2 to 1
                                logging.info(f"AI extraction successful after JSON cleanup for {url}")
                                return valid_modules
                    except Exception as cleanup_error:
                        save_debug_info(url, content, response_text, str(cleanup_error), "json_cleanup_failure")
        
        except Exception as e:
            logging.error(f"AI extraction failed for {url}: {e}")
            save_debug_info(url, content, None, str(e), "ai_extraction_failure")
    
    # Try heuristic extraction
    logging.info(f"Attempting heuristic extraction for {url}")
    heuristic_result = extract_modules_heuristically(content)
    if heuristic_result and isinstance(heuristic_result, list) and len(heuristic_result) >= 1:  # Reduced from 2 to 1
        # Validate heuristic results
        valid_modules = []
        for module in heuristic_result:
            if (isinstance(module, dict) and 
                module.get('module') and len(module.get('module', '')) > 3 and
                module.get('Description') and len(module.get('Description', '')) > 30 and
                module.get('Submodules') and isinstance(module.get('Submodules'), dict) and
                len(module.get('Submodules', {})) >= 1):
                valid_modules.append(module)
        
        if len(valid_modules) >= 1:  # Reduced from 2 to 1
            logging.info(f"Heuristic extraction successful for {url}")
            return valid_modules
    
    # If we reach here, we couldn't extract meaningful content
    logging.warning(f"Could not extract sufficient detailed modules for {url}")
    save_debug_info(url, content, None, "No meaningful modules could be extracted", "no_modules_extracted")
    return None

def clean_content(text):
    """Clean content to remove garbled text and irrelevant characters."""
    if not text:
        return ""
    
    # Remove non-printable characters and excessive special characters
    text = re.sub(r'[^\w\s\-.,!?:;()\[\]{}"\'/]', ' ', text)
    
    # Remove lines with too many special characters (likely garbled)
    lines = text.split('\n')
    clean_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Skip lines that are mostly special characters or very short
        if len(line) < 10:
            continue
            
        # Count alphanumeric characters vs special characters
        alnum_count = sum(1 for c in line if c.isalnum())
        total_count = len(line)
        
        # Keep lines that are at least 60% alphanumeric
        if total_count > 0 and (alnum_count / total_count) >= 0.6:
            clean_lines.append(line)
    
    return '\n'.join(clean_lines)

def create_fallback_modules(text, url):
    """Create meaningful modules when AI fails to return JSON."""
    # Clean the content first
    clean_text = clean_content(text)
    
    if not clean_text or len(clean_text.strip()) < 50:
        return [{
            "module": "Content Extraction Issue",
            "Description": "The content from this URL could not be properly extracted or contains mostly unreadable text.",
            "Submodules": {
                "Recommendation": "Try accessing the URL directly in a browser or check if the content requires authentication."
            }
        }]
    
    lines = clean_text.split('\n')
    modules = []
    current_module = None
    
    # Look for meaningful headers and content
    for line in lines[:30]:  # Check first 30 clean lines
        line = line.strip()
        if not line or len(line) < 5:
            continue
        
        # Identify potential headers (short lines with title case)
        words = line.split()
        if (len(words) <= 6 and 
            len(line) < 80 and
            any(word[0].isupper() for word in words if len(word) > 2) and
            not line.endswith('.') and
            ':' not in line):
            
            # Save previous module
            if current_module and current_module["Submodules"]:
                modules.append(current_module)
            
            # Start new module
            current_module = {
                "module": line,
                "Description": f"Information and guidance about {line.lower()}",
                "Submodules": {}
            }
            
        elif current_module and len(line) > 20 and len(line) < 300:
            # Add meaningful content as submodules
            if len(current_module["Submodules"]) < 3:  # Limit submodules
                submodule_key = f"Topic {len(current_module['Submodules']) + 1}"
                # Take first sentence or reasonable chunk
                content = line.split('.')[0] if '.' in line else line
                if len(content) > 150:
                    content = content[:150] + "..."
                current_module["Submodules"][submodule_key] = content
    
    # Add the last module if it has content
    if current_module and current_module["Submodules"]:
        modules.append(current_module)
    
    # If no structured modules found, create a summary module
    if not modules:
        # Extract first few meaningful sentences
        sentences = []
        for line in lines[:10]:
            if len(line) > 30 and len(line) < 200:
                sentences.append(line)
                if len(sentences) >= 3:
                    break
        
        if sentences:
            modules = [{
                "module": "Documentation Content",
                "Description": "Main content extracted from the documentation page",
                "Submodules": {
                    f"Section {i+1}": sent[:100] + "..." if len(sent) > 100 else sent
                    for i, sent in enumerate(sentences[:3])
                }
            }]
        else:
            modules = [{
                "module": "Page Content",
                "Description": "Content was extracted but may require manual review",
                "Submodules": {
                    "Note": "The page content could not be automatically structured. Please visit the URL directly for better access."
                }
            }]
    
    logging.info(f"Created {len(modules)} meaningful fallback modules for {url}")
    return modules

def infer_modules(docs):
    """
    Use Azure OpenAI LLM via LangChain to extract modules and submodules from documentation text.
    """
    results = []
    
    for url, text in docs.items():
        if text.startswith("ERROR:"):
            logging.warning(f"Skipping {url} due to extraction error: {text}")
            continue
        
        # Clean and truncate content
        clean_text = clean_content(text)
        if len(clean_text) > 4000:
            clean_text = clean_text[:4000] + "..."
        
        if not clean_text or len(clean_text.strip()) < 50:
            logging.warning(f"No meaningful content found for {url}")
            fallback_modules = create_fallback_modules(text, url)
            results.extend(fallback_modules)
            continue
        
        # Try AI extraction first
        ai_modules = try_ai_extraction(clean_text, url)
        if ai_modules:
            results.extend(ai_modules)
        else:
            # Fallback to heuristic extraction
            logging.warning(f"AI extraction failed for {url}, using fallback method")
            fallback_modules = create_fallback_modules(clean_text, url)
            results.extend(fallback_modules)
    
    return results

def try_ai_extraction(text, url):
    """Try to extract modules using AI with a more reliable prompt."""
    prompt_template = ChatPromptTemplate.from_template(
        """
Analyze this documentation content and create a structured JSON response.

Instructions:
- Identify 1-3 main topics/sections as modules
- For each module, find 1-3 related subtopics as submodules  
- Use clear, descriptive names
- Keep descriptions concise but informative
- Respond with ONLY valid JSON, no other text

Content:
{doc_content}

Respond with JSON in this exact format:
[{{"module": "Topic Name", "Description": "Brief description", "Submodules": {{"Subtopic": "Brief description"}}}}]
"""
    )
    
    try:
        prompt = prompt_template.format(doc_content=text)
        response = llm.invoke(prompt)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        logging.info(f"AI response for {url}: {response_text[:200]}...")
        
        # Clean the response
        response_text = response_text.strip()
        
        # Remove markdown formatting
        if '```' in response_text:
            response_text = re.sub(r'```[a-z]*\n?', '', response_text)
            response_text = re.sub(r'\n?```', '', response_text)
        
        # Try to extract JSON
        json_match = re.search(r'(\[.*\])', response_text, re.DOTALL)
        if json_match:
            try:
                modules = json.loads(json_match.group(1))
                if isinstance(modules, list) and len(modules) > 0:
                    # Validate that modules have required structure
                    valid_modules = []
                    for module in modules:
                        if (isinstance(module, dict) and 
                            'module' in module and 
                            'Description' in module and 
                            'Submodules' in module):
                            valid_modules.append(module)
                    
                    if valid_modules:
                        logging.info(f"Successfully extracted {len(valid_modules)} valid modules from {url}")
                        return valid_modules
            except json.JSONDecodeError as e:
                logging.error(f"JSON decode error for {url}: {e}")
        
        # Try parsing entire response
        try:
            modules = json.loads(response_text)
            if isinstance(modules, list) and len(modules) > 0:
                logging.info(f"Successfully extracted {len(modules)} modules from {url}")
                return modules
        except json.JSONDecodeError:
            pass
        
        logging.warning(f"Could not extract valid JSON from AI response for {url}")
        return None
        
    except Exception as e:
        logging.error(f"AI extraction failed for {url}: {e}")
        return None

def extract_modules_from_text(text):
    """
    Extract modules and submodules from a single documentation text using the LLM.
    Returns a list of module dicts or None if extraction fails.
    """
    clean_text = clean_content(text)
    ai_modules = try_ai_extraction(clean_text, "test_url")
    if ai_modules:
        return ai_modules
    else:
        return create_fallback_modules(clean_text, "test_url")

def test_extract_modules_from_text():
    """Simple test for extract_modules_from_text with a mock doc."""
    mock_doc = """
Account Settings
Includes features and tools for managing Instagram account preferences, privacy, and credentials.
Change Username: Explains how to update your Instagram handle and display name via account settings.
Content Sharing
Covers tools and workflows for creating, editing, and publishing content on Instagram.
Creating Reels: Provides instructions for recording, editing, and sharing short-form video content using Reels.
Tagging Users: Details how to tag individuals or businesses in posts and stories for engagement.
"""
    modules = extract_modules_from_text(mock_doc)
    print("LLM Output:", modules)

if __name__ == "__main__":
    test_extract_modules_from_text()
